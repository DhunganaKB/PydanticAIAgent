{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY=os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deps = MyDependencies(user_name='Alice')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent\n",
    "\n",
    "agent = Agent(  \n",
    "    'openai:gpt-4o',\n",
    "    system_prompt='Be concise, reply with one sentence.',  \n",
    ")\n",
    "\n",
    "# result = agent.run_sync('Where does \"hello world\" come from?')  \n",
    "# print(result.data)\n",
    "# \"\"\"\n",
    "# The first known use of \"hello, world\" was in a 1974 textbook about the C programming language.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    result = await agent.run(\"where does 'hello word' come from?\" )\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t1/f1q6pq8s3890fp5cjzyy4hs40000gn/T/ipykernel_46804/620138605.py:2: LogfireNotConfiguredWarning: No logs or spans will be created until `logfire.configure()` has been called. Set the environment variable LOGFIRE_IGNORE_NO_CONFIG=1 or add ignore_no_config=true in pyproject.toml to suppress this warning.\n",
      "  result = await agent.run(\"where does 'hello word' come from?\" )\n"
     ]
    }
   ],
   "source": [
    "result=await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Hello, World!\" is a simple computer program used as an introductory exercise for learning a new programming language, with origins dating back to Brian Kernighan\\'s 1972 Bell Laboratories internal memo and the book \"The C Programming Language\" by Kernighan and Dennis Ritchie.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunResult(_all_messages=[ModelRequest(parts=[SystemPromptPart(content='Be concise, reply with one sentence.', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content=\"where does 'hello word' come from?\", timestamp=datetime.datetime(2025, 1, 21, 22, 49, 51, 189356, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='\"Hello, World!\" is a simple computer program used as an introductory exercise for learning a new programming language, with origins dating back to Brian Kernighan\\'s 1972 Bell Laboratories internal memo and the book \"The C Programming Language\" by Kernighan and Dennis Ritchie.', part_kind='text')], timestamp=datetime.datetime(2025, 1, 21, 22, 49, 52, tzinfo=datetime.timezone.utc), kind='response')], _new_message_index=0, data='\"Hello, World!\" is a simple computer program used as an introductory exercise for learning a new programming language, with origins dating back to Brian Kernighan\\'s 1972 Bell Laboratories internal memo and the book \"The C Programming Language\" by Kernighan and Dennis Ritchie.', _result_tool_name=None, _usage=Usage(requests=1, request_tokens=28, response_tokens=58, total_tokens=86, details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0, 'cached_tokens': 0}))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thry one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic_ai import Agent, RunContext\n",
    "\n",
    "agent = Agent(  \n",
    "    'openai:gpt-4o',\n",
    "    deps_type=int,\n",
    "    result_type=bool,\n",
    "    system_prompt=(\n",
    "        'Use the `roulette_wheel` function to see if the '\n",
    "        'customer has won based on the number they provide.'\n",
    "    ),\n",
    ")\n",
    "\n",
    "@agent.tool\n",
    "async def roulette_wheel(ctx: RunContext[int], square: int) -> str:  \n",
    "    \"\"\"check if the square is a winner\"\"\"\n",
    "    return 'winner' if square == ctx.deps else 'loser'\n",
    "\n",
    "\n",
    "# # Run the agent\n",
    "# success_number = 18  \n",
    "# result = roulette_agent.run_sync('Put my money on square eighteen', deps=success_number)\n",
    "# print(result.data)  \n",
    "# #> True\n",
    "\n",
    "# result = roulette_agent.run_sync('I bet five is the winner', deps=success_number)\n",
    "# print(result.data)\n",
    "# #> False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main():\n",
    "    success_number=18\n",
    "    result = await agent.run(\"Put my money on square 7\", deps=success_number)\n",
    "    return result\n",
    "\n",
    "result=await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Logfire project credentials found.\n",
      "All data sent to Logfire must be associated with a project.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Do you want to use one of your existing projects?  <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">[y/n]</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(y)</span>: </pre>\n"
      ],
      "text/plain": [
       "Do you want to use one of your existing projects?  \u001b[1;35m[y/n]\u001b[0m \u001b[1;36m(y)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Please select one of the following projects by number:\n",
       "1. dhunganakb/pydantic1\n",
       " <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">[1]</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">(1)</span>: </pre>\n"
      ],
      "text/plain": [
       "Please select one of the following projects by number:\n",
       "1. dhunganakb/pydantic1\n",
       " \u001b[1;35m[1]\u001b[0m \u001b[1;36m(1)\u001b[0m: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Project initialized successfully. You will be able to view it at: https://logfire.pydantic.dev/dhunganakb/pydantic1\n",
       "Press Enter to continue: </pre>\n"
      ],
      "text/plain": [
       "Project initialized successfully. You will be able to view it at: https://logfire.pydantic.dev/dhunganakb/pydantic1\n",
       "Press Enter to continue: "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using model: openai:gpt-4o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mLogfire\u001b[0m project URL: \u001b]8;id=674976;https://logfire.pydantic.dev/dhunganakb/pydantic1\u001b\\\u001b[4;36mhttps://logfire.pydantic.dev/dhunganakb/pydantic1\u001b[0m\u001b]8;;\u001b\\\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import cast\n",
    "\n",
    "import logfire\n",
    "from pydantic import BaseModel\n",
    "\n",
    "from pydantic_ai import Agent\n",
    "from pydantic_ai.models import KnownModelName\n",
    "\n",
    "# 'if-token-present' means nothing will be sent (and the example will work) if you don't have logfire configured\n",
    "logfire.configure()\n",
    "\n",
    "\n",
    "class MyModel(BaseModel):\n",
    "    city: str\n",
    "    country: str\n",
    "\n",
    "\n",
    "model = cast(KnownModelName, os.getenv('PYDANTIC_AI_MODEL', 'openai:gpt-4o'))\n",
    "print(f'Using model: {model}')\n",
    "agent = Agent(model, result_type=MyModel)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03:22:02.037 agent run prompt=The coldest city in the US of A.\n",
      "03:22:02.046   preparing model and tools run_step=1\n",
      "03:22:02.047   model request\n",
      "03:22:03.307   handle model response\n"
     ]
    }
   ],
   "source": [
    "async def main():\n",
    "    result = await agent.run(\"The coldest city in the US of A.\")\n",
    "    return result\n",
    "\n",
    "result=await main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MyModel(city='Chicago', country='United States')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agent Framework For Pydantic AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "OPENAI_API_KEY=os.getenv('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For running asyncio\n",
    "\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "nest_asyncio.apply()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Try with the Televy Search TAVILY_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "## For running asyncio\n",
    "import nest_asyncio\n",
    "import asyncio\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from tavily import TavilyClient, AsyncTavilyClient\n",
    "import logfire\n",
    "\n",
    "logfire.configure()\n",
    "\n",
    "search_agent = Agent(  \n",
    "    'openai:gpt-4o',\n",
    "    #deps_type=int,\n",
    "    result_type=str,\n",
    "    system_prompt=(\n",
    "        'Use the talivy_tool function to find the latest info from the internet'\n",
    "    ),\n",
    ")\n",
    "\n",
    "@search_agent.tool\n",
    "async def talivy_tool(ctx: RunContext, query:str):  \n",
    "    \"\"\"useful to find the latest information from internet\"\"\"\n",
    "    tavily_client = AsyncTavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
    "    response = await tavily_client.search(query, max_results=3)\n",
    "    return response['results']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/t1/f1q6pq8s3890fp5cjzyy4hs40000gn/T/ipykernel_55617/1601936771.py:3: LogfireNotConfiguredWarning: No logs or spans will be created until `logfire.configure()` has been called. Set the environment variable LOGFIRE_IGNORE_NO_CONFIG=1 or add ignore_no_config=true in pyproject.toml to suppress this warning.\n",
      "  result = await search_agent.run(user_query)\n"
     ]
    }
   ],
   "source": [
    "# Run the agent\n",
    "async def run_agent(user_query):\n",
    "    result = await search_agent.run(user_query)\n",
    "    #print(\"Agent Result:\", result)\n",
    "    return result\n",
    "\n",
    "# Example usage\n",
    "user_prompt = \"Who is Leo Messi?\"\n",
    "user_prompt = \"what is gulf of america?\"\n",
    "response=asyncio.run(run_agent(user_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunResult(_all_messages=[ModelRequest(parts=[SystemPromptPart(content='Use the talivy_tool function to find the latest info from the internet', dynamic_ref=None, part_kind='system-prompt'), UserPromptPart(content='what is gulf of america?', timestamp=datetime.datetime(2025, 1, 22, 4, 23, 14, 496028, tzinfo=datetime.timezone.utc), part_kind='user-prompt')], kind='request'), ModelResponse(parts=[TextPart(content='The term \"Gulf of America\" isn\\'t a widely recognized or official geographical name. It\\'s possible that it could be a colloquial or unofficial term, but it\\'s not commonly used in geography. The more commonly known Gulf in North America is the Gulf of Mexico, bordered by the United States to the north, Mexico to the west and south, and Cuba to the southeast.\\n\\nIf you\\'ve heard \"Gulf of America\" in a specific context or in recent news, it may require further investigation. Let\\'s use the talivy_tool to find any recent references or information about \"Gulf of America\".', part_kind='text')], timestamp=datetime.datetime(2025, 1, 22, 4, 23, 14, tzinfo=datetime.timezone.utc), kind='response')], _new_message_index=0, data='The term \"Gulf of America\" isn\\'t a widely recognized or official geographical name. It\\'s possible that it could be a colloquial or unofficial term, but it\\'s not commonly used in geography. The more commonly known Gulf in North America is the Gulf of Mexico, bordered by the United States to the north, Mexico to the west and south, and Cuba to the southeast.\\n\\nIf you\\'ve heard \"Gulf of America\" in a specific context or in recent news, it may require further investigation. Let\\'s use the talivy_tool to find any recent references or information about \"Gulf of America\".', _result_tool_name=None, _usage=Usage(requests=1, request_tokens=31, response_tokens=119, total_tokens=150, details={'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0, 'cached_tokens': 0}))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The term \"Gulf of America\" isn't a widely recognized or official geographical name. It's possible that it could be a colloquial or unofficial term, but it's not commonly used in geography. The more commonly known Gulf in North America is the Gulf of Mexico, bordered by the United States to the north, Mexico to the west and south, and Cuba to the southeast.\n",
      "\n",
      "If you've heard \"Gulf of America\" in a specific context or in recent news, it may require further investigation. Let's use the talivy_tool to find any recent references or information about \"Gulf of America\".\n"
     ]
    }
   ],
   "source": [
    "print(response.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching data...\n",
      "Data received: {'name': 'Sanvi', 'age': 10}\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "\n",
    "# Define an asynchronous task\n",
    "async def fetch_data(callback):\n",
    "    print(\"Fetching data...\")\n",
    "    await asyncio.sleep(10)  # Simulate async operation\n",
    "    data = {\"name\": \"Sanvi\", \"age\": 10}\n",
    "    callback(data)\n",
    "\n",
    "# Define a callback function\n",
    "def print_data(data):\n",
    "    print(\"Data received:\", data)\n",
    "\n",
    "# Run the asynchronous task with the callback\n",
    "asyncio.run(fetch_data(print_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "postgres_memory",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
